# Optimizaci√≥n de un Modelo de Regresi√≥n Lineal Simple

## Descripci√≥n General

Este proyecto implementa una soluci√≥n completa en Python para entrenar un modelo de **regresi√≥n lineal simple** a partir de datos sint√©ticos. Se abordan dos m√©todos fundamentales para estimar los par√°metros √≥ptimos del modelo:

- **C√°lculo cerrado** mediante la **f√≥rmula normal**.
- **Optimizaci√≥n iterativa** utilizando el **descenso de gradiente**.

Incluye validaci√≥n de datos, manejo de errores personalizados, visualizaci√≥n de los modelos y evoluci√≥n del error, adem√°s de una comparaci√≥n entre ambos enfoques.

## Objetivos

- Generar datos sint√©ticos reproducibles.
- Implementar el modelo de regresi√≥n lineal mediante dos m√©todos.
- Calcular y graficar la funci√≥n de costo.
- Visualizar comparativamente ambos modelos.
- Aplicar manejo robusto de excepciones.
- Evaluar rendimiento y precisi√≥n.

## M√≥dulos y Funcionalidades

### 1. Generaci√≥n de Datos
- Modelo:  
  **ùë¶ = 4 + 3ùë• + Œµ**  
  con Œµ = ruido gaussiano.
- Generaci√≥n de 100 puntos usando `NumPy`.
- Validaciones sobre cantidad de muestras, rango y desviaci√≥n est√°ndar del ruido.
- Datos reproducibles mediante semilla (`np.random.seed`).
- Inclusi√≥n del t√©rmino de sesgo (columna de unos en X).

### 2. C√°lculo Cerrado (Ecuaci√≥n Normal)
- Implementaci√≥n de:  
  **ùõΩ = (X·µÄX)‚Åª¬πX·µÄy**
- C√°lculo de par√°metros √≥ptimos `Œ∏‚ÇÄ` y `Œ∏‚ÇÅ`.
- Manejo de errores si la matriz es singular (no invertible).
- Validaci√≥n del formato y dimensi√≥n de los datos.

### 3. Descenso de Gradiente
- Derivaci√≥n del gradiente del MSE.
- Algoritmo iterativo con tasa de aprendizaje y n√∫mero de iteraciones configurables.
- Inicializaci√≥n de par√°metros en cero.
- C√°lculo y registro del costo (`MSE`) en cada iteraci√≥n.
- Validaciones y manejo de errores.

### 4. Visualizaci√≥n
- Gr√°fico comparativo:  
  - Datos reales  
  - Recta obtenida por f√≥rmula cerrada  
  - Recta obtenida por descenso de gradiente  
- Curva de evoluci√≥n del costo a lo largo de las iteraciones.

### 5. Manejo de Excepciones
- Se define la clase `ErrorFormatoDatosInvalido`.
- Uso extensivo de bloques `try-except` para controlar errores comunes y cr√≠ticos.
- Mensajes informativos para facilitar la depuraci√≥n.

## Resultados Esperados

| M√©todo              | Par√°metros (Œ∏‚ÇÄ, Œ∏‚ÇÅ)       | Costo Final (MSE) |
|------------------------|----------------------------|-------------------|
| C√°lculo Cerrado     | `[Œ≤‚ÇÄ, Œ≤‚ÇÅ]`                 | `‚âà XX.XXXX`       |
| Descenso Gradiente  | `[Œ∏‚ÇÄ, Œ∏‚ÇÅ]`                 | `‚âà XX.XXXX`       |

> **Nota**: El costo puede variar levemente seg√∫n el ruido generado aleatoriamente.

## Complejidad y Elecci√≥n del M√©todo

| M√©todo              | Complejidad Big O         | Ventajas                                 |
|---------------------|----------------------------|------------------------------------------|
| C√°lculo Cerrado     | O(n¬≥)                      | Preciso, r√°pido con pocos datos          |
| Descenso Gradiente  | O(n¬∑i), i = iteraciones    | Escalable, ideal para grandes datasets   |

### Elecci√≥n sugerida:
- **Problemas peque√±os o an√°lisis offline** ‚Üí **C√°lculo Cerrado**
- **Datos masivos o transmisi√≥n continua** ‚Üí **Descenso de Gradiente**

## Evidencias

El proyecto genera:
- Visualizaci√≥n de los modelos ajustados.
- Gr√°fico de la evoluci√≥n del error (funci√≥n de costo).
- Impresiones en consola de los par√°metros y costos finales.
- Mensajes de error controlados y expl√≠citos.

## Requisitos

- Python 3.11.2
  - numpy
  - matplotlib

## Autor

Henzo Alejandro Arru√© Mu√±oz

## Licencia

GPLv3
